% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cas_update.R
\name{cas_update}
\alias{cas_update}
\title{Update corpus}
\usage{
cas_update(extract_links_partial, extractors, wait = 3, user_agent = NULL, ...)
}
\arguments{
\item{extract_links_partial}{A partial function, typically created with
\code{purrr::partial(.f = cas_extract_links)}, followed by the paramters
originally used by \code{cas_extract_links()}. See examples.}

\item{extractors}{A named list of functions. See examples for details.}

\item{wait}{Defaults to 1. Number of seconds to wait between downloading one
page and the next. Can be increased to reduce server load, or can be set to
0 when this is not an issue.}

\item{user_agent}{Defaults to NULL. If given, passed to download method.}

\item{...}{Passed to \code{cas_get_db_file()}.}
}
\description{
Currently supports only update when re-downloading index urls is expected to
bring new articles. It takes the first urls for each index group, and
continues downloading new index pages as long as new links are found in each
page. If no new link is found, it stops downloading and moves to the next
index group.
}
\examples{

# Example of extract_links_partial:
extract_links_partial <- purrr::partial(
  .f = cas_extract_links,
  reverse_order = TRUE,
  container = "div",
  container_class = "hentry h-entry hentry_event",
  exclude_when = c("/photos", "/videos"),
  domain = "http://en.kremlin.ru/"
)

}
